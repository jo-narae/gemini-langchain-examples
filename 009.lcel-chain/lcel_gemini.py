import os
from pathlib import Path
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from typing import Literal
from pydantic import BaseModel, Field

# -----------------------------
# 1) í™˜ê²½ì„¤ì •
# -----------------------------
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# -----------------------------
# 2) Gemini ëª¨ë¸ ì´ˆê¸°í™”
# -----------------------------
model = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite"),
    temperature=0.7,
    google_api_key=api_key,
)
print("âœ… Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

def test_basic_messages():
    """ê¸°ë³¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ë©”ì‹œì§€ì™€ ëª¨ë¸ í˜¸ì¶œ")
    print("="*50)

    messages = [
        SystemMessage(content="ë„ˆëŠ” ë¯¸ë…€ì™€ ì•¼ìˆ˜ì— ë‚˜ì˜¤ëŠ” ë¯¸ë…€ì•¼. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."),
        HumanMessage(content="ì•ˆë…•? ì €ëŠ” ê°œìŠ¤í†¤ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ ì €ë… ê°™ì´ ë¨¹ì„ê¹Œìš”?"),
    ]

    result = model.invoke(messages)
    print(f"ğŸ¤– AI ì‘ë‹µ: {result.content}")
    return result

def test_output_parser():
    """ì¶œë ¥ íŒŒì„œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¶œë ¥ íŒŒì„œ ì‚¬ìš©")
    print("="*50)

    parser = StrOutputParser()

    messages = [
        SystemMessage(content="ë„ˆëŠ” ë¯¸ë…€ì™€ ì•¼ìˆ˜ì— ë‚˜ì˜¤ëŠ” ë¯¸ë…€ì•¼. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."),
        HumanMessage(content="ì•ˆë…•? ì €ëŠ” ê°œìŠ¤í†¤ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ ì €ë… ê°™ì´ ë¨¹ì„ê¹Œìš”?"),
    ]

    result = model.invoke(messages)          # AIMessage
    parsed_result = parser.invoke(result)    # ë¬¸ìì—´ë¡œ íŒŒì‹±
    print(f"ğŸ¤– íŒŒì‹±ëœ ì‘ë‹µ: {parsed_result}")
    return parsed_result

def test_chain_basic():
    """ê¸°ë³¸ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 3: ê¸°ë³¸ ì²´ì¸ (ëª¨ë¸ | íŒŒì„œ)")
    print("="*50)

    parser = StrOutputParser()
    chain = model | parser

    messages = [
        SystemMessage(content="ë„ˆëŠ” ë¯¸ë…€ì™€ ì•¼ìˆ˜ì— ë‚˜ì˜¤ëŠ” ë¯¸ë…€ì•¼. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."),
        HumanMessage(content="ì•ˆë…•? ì €ëŠ” ê°œìŠ¤í†¤ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ ì €ë… ê°™ì´ ë¨¹ì„ê¹Œìš”?"),
    ]

    result = chain.invoke(messages)          # ìµœì¢… ë¬¸ìì—´
    print(f"ğŸ¤– ì²´ì¸ ì‘ë‹µ: {result}")
    return result

def test_prompt_template():
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 4: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©")
    print("="*50)

    system_template = "ë„ˆëŠ” {story}ì— ë‚˜ì˜¤ëŠ” {character_a} ì—­í• ì´ë‹¤. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."
    human_template  = "ì•ˆë…•? ì €ëŠ” {character_b}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ {activity} ê°™ì´ í• ê¹Œìš”?"

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("user", human_template),
    ])

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê²°ê³¼ í™•ì¸
    prompt_value = prompt_template.invoke({
        "story": "ë¯¸ë…€ì™€ ì•¼ìˆ˜",
        "character_a": "ë¯¸ë…€",
        "character_b": "ì•¼ìˆ˜",
        "activity": "ì €ë…"
    })
    # ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ:
    print("ğŸ“‹ ìƒì„±ëœ ë©”ì‹œì§€ë“¤:", prompt_value.to_messages())
    # ë˜ëŠ” print("ğŸ“‹ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸(ë¬¸ìì—´):", prompt_value.to_string())

    return prompt_template

def test_complete_chain():
    """ì™„ì „í•œ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 5: ì™„ì „í•œ ì²´ì¸ (í”„ë¡¬í”„íŠ¸ | ëª¨ë¸ | íŒŒì„œ)")
    print("="*50)

    system_template = "ë„ˆëŠ” {story}ì— ë‚˜ì˜¤ëŠ” {character_a} ì—­í• ì´ë‹¤. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."
    human_template  = "ì•ˆë…•? ì €ëŠ” {character_b}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ {activity} ê°™ì´ í• ê¹Œìš”?"

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("user", human_template),
    ])

    parser = StrOutputParser()
    chain = prompt_template | model | parser

    # ì•¼ìˆ˜ì™€ì˜ ëŒ€í™”
    print("\nğŸŒ¹ ì•¼ìˆ˜ì™€ì˜ ëŒ€í™”:")
    result1 = chain.invoke({
        "story": "ë¯¸ë…€ì™€ ì•¼ìˆ˜",
        "character_a": "ë¯¸ë…€",
        "character_b": "ì•¼ìˆ˜",
        "activity": "ì €ë…"
    })
    print(f"ğŸ¤– ë¯¸ë…€ì˜ ì‘ë‹µ: {result1}")

    # ê°œìŠ¤í†¤ê³¼ì˜ ëŒ€í™”
    print("\nğŸ’ª ê°œìŠ¤í†¤ê³¼ì˜ ëŒ€í™”:")
    result2 = chain.invoke({
        "story": "ë¯¸ë…€ì™€ ì•¼ìˆ˜",
        "character_a": "ë¯¸ë…€",
        "character_b": "ê°œìŠ¤í†¤",
        "activity": "ì €ë…"
    })
    print(f"ğŸ¤– ë¯¸ë…€ì˜ ì‘ë‹µ: {result2}")

    return chain

def test_structured_output():
    """êµ¬ì¡°í™”ëœ ì¶œë ¥ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ“ í…ŒìŠ¤íŠ¸ 6: êµ¬ì¡°í™”ëœ ì¶œë ¥ (Pydantic ëª¨ë¸)")
    print("="*50)

    class Adlib(BaseModel):
        """ìŠ¤í† ë¦¬ ì„¤ì •ê³¼ ì‚¬ìš©ì ì…ë ¥ì— ë°˜ì‘í•˜ëŠ” ëŒ€ì‚¬ë¥¼ ë§Œë“œëŠ” í´ë˜ìŠ¤"""
        answer: str = Field(description="ìŠ¤í† ë¦¬ ì„¤ì •ê³¼ ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ê¸°ë¡ì— ë”°ë¼ ìƒì„±ëœ ëŒ€ì‚¬")
        main_emotion: Literal["ê¸°ì¨", "ë¶„ë…¸", "ìŠ¬í””", "ê³µí¬", "ëƒ‰ì†Œ", "ë¶ˆì¾Œ", "ì¤‘ë¦½"] = Field(description="ëŒ€ì‚¬ì˜ ì£¼ìš” ê°ì •")
        main_emotion_intensity: float = Field(description="ëŒ€ì‚¬ì˜ ì£¼ìš” ê°ì •ì˜ ê°•ë„ (0.0 ~ 1.0)")

    system_template = "ë„ˆëŠ” {story}ì— ë‚˜ì˜¤ëŠ” {character_a} ì—­í• ì´ë‹¤. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼."
    human_template  = "ì•ˆë…•? ì €ëŠ” {character_b}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ {activity} ê°™ì´ í• ê¹Œìš”?"

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("user", human_template),
    ])

    try:
        # LangChainì´ Geminiì˜ response schemaë¥¼ í™œìš©í•˜ì—¬ JSON êµ¬ì¡°ë¡œ ê°•ì œ
        structured_llm = model.with_structured_output(Adlib)
        adlib_chain = prompt_template | structured_llm

        result = adlib_chain.invoke({
            "story": "ë¯¸ë…€ì™€ ì•¼ìˆ˜",
            "character_a": "ë²¨",
            "character_b": "ê°œìŠ¤í†¤",
            "activity": "ì €ë…"
        })

        print(f"ğŸ¤– êµ¬ì¡°í™”ëœ ì‘ë‹µ:")
        print(f"   ğŸ’¬ ëŒ€ì‚¬: {result.answer}")
        print(f"   ğŸ˜Š ê°ì •: {result.main_emotion}")
        print(f"   ğŸ“Š ê°•ë„: {result.main_emotion_intensity}")

    except Exception as e:
        # í™˜ê²½/ë²„ì „ì— ë”°ë¼ ë¯¸ì§€ì›ì¼ ìˆ˜ ìˆì–´ ì•ˆì „í•œ í´ë°± ì œê³µ
        print(f"âš ï¸ êµ¬ì¡°í™”ëœ ì¶œë ¥ ì§€ì› ì•ˆë¨: {e}")
        print("ğŸ’¡ ì¼ë°˜ ì²´ì¸ìœ¼ë¡œ ëŒ€ì²´ ì‹¤í–‰:")

        parser = StrOutputParser()
        fallback_chain = prompt_template | model | parser

        result = fallback_chain.invoke({
            "story": "ë¯¸ë…€ì™€ ì•¼ìˆ˜",
            "character_a": "ë²¨",
            "character_b": "ê°œìŠ¤í†¤",
            "activity": "ì €ë…"
        })
        print(f"ğŸ¤– ì¼ë°˜ ì‘ë‹µ: {result}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\nğŸ­ LCEL ì²´ì¸ ì˜ˆì œ - Gemini API ë²„ì „")
    print("="*50)

    test_basic_messages()
    test_output_parser()
    test_chain_basic()
    test_prompt_template()
    test_complete_chain()
    test_structured_output()

    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
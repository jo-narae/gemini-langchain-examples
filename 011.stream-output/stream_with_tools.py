"""
LangChain Tools ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì œ

ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì—ì„œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ íŒ¨í„´:
1. ë„êµ¬ í˜¸ì¶œ ì²­í¬ë“¤ì„ ëª¨ìœ¼ê¸° (gathered += chunk)
2. ë„êµ¬ ì‹¤í–‰
3. ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
"""

import os
import sys

# Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from datetime import datetime
import pytz
from pathlib import Path

# í™˜ê²½ì„¤ì •
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
os.environ["GOOGLE_API_KEY"] = api_key

print("=" * 60)
print("LangChain Tools ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì œ")
print("=" * 60)
print()

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite"),
    temperature=0.7,
)

# ë„êµ¬ ì •ì˜
@tool
def get_current_time(timezone: str, location: str) -> str:
    """í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        timezone: íƒ€ì„ì¡´ (ì˜ˆ: 'Asia/Seoul')
        location: ì§€ì—­ëª…
    """
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        result = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
        print(f"  ğŸ• {result}")
        return result
    except Exception as e:
        return f"ì‹œê°„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

# ë„êµ¬ ì„¤ì •
tools = [get_current_time]
tool_dict = {"get_current_time": get_current_time}
llm_with_tools = llm.bind_tools(tools)

print("âœ… ëª¨ë¸ê³¼ ë„êµ¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
print()

# -----------------------------
# í•µì‹¬ íŒ¨í„´: ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ ë„êµ¬ ì‚¬ìš©
# -----------------------------
print("=" * 60)
print("ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ ë„êµ¬ ì‚¬ìš©í•˜ê¸°")
print("=" * 60)
print()

messages = [
    SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ ë°˜ë“œì‹œ get_current_time ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì •í™•í•œ ì‹œê°„ì„ ì¡°íšŒí•´ì•¼ í•œë‹¤. ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ë¼."),
    HumanMessage("ì„œìš¸ì˜ í˜„ì¬ ì‹œê°ì„ ì•Œë ¤ì£¼ê³ , ì„œìš¸ì˜ ì—­ì‚¬ì™€ ì£¼ìš” ê´€ê´‘ì§€ì— ëŒ€í•´ì„œë„ ìì„¸íˆ ì„¤ëª…í•´ì¤˜"),
]

print("ğŸ’¬ ì§ˆë¬¸: ì„œìš¸ì˜ í˜„ì¬ ì‹œê°ì„ ì•Œë ¤ì£¼ê³ , ì„œìš¸ì˜ ì—­ì‚¬ì™€ ì£¼ìš” ê´€ê´‘ì§€ì— ëŒ€í•´ì„œë„ ìì„¸íˆ ì„¤ëª…í•´ì¤˜")
print()

# 1ë‹¨ê³„: ë„êµ¬ í˜¸ì¶œ ì²­í¬ ëª¨ìœ¼ê¸°
print("ğŸ“ 1ë‹¨ê³„: ë„êµ¬ í˜¸ì¶œ ì²­í¬ ëª¨ìœ¼ê¸°")
response_stream = llm_with_tools.stream(messages)

is_first = True
for chunk in response_stream:
    if is_first:
        is_first = False
        gathered = chunk
    else:
        gathered += chunk  # í•µì‹¬: ì²­í¬ë¥¼ ëˆ„ì 

print(f"  âœ… ì²­í¬ ëª¨ìœ¼ê¸° ì™„ë£Œ")
print(f"  ğŸ“‹ ë„êµ¬ í˜¸ì¶œ: {gathered.tool_calls}")
print()

messages.append(gathered)

# 2ë‹¨ê³„: ë„êµ¬ ì‹¤í–‰
if gathered.tool_calls:
    print("ğŸ“ 2ë‹¨ê³„: ë„êµ¬ ì‹¤í–‰")

    for tool_call in gathered.tool_calls:
        tool_name = tool_call["name"]
        selected_tool = tool_dict[tool_name]
        tool_result = selected_tool.invoke(tool_call["args"])

        tool_msg = ToolMessage(
            content=tool_result,
            tool_call_id=tool_call["id"]
        )
        messages.append(tool_msg)

    print()

    # 3ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
    print("ğŸ“ 3ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°")
    print("ğŸ¯ ë‹µë³€: ", end='')

    for chunk in llm_with_tools.stream(messages):
        print(chunk.content, end='', flush=True)

    print()

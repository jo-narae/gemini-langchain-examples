"""
LangChain ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ê¸°ë³¸ ì˜ˆì œ

ì‹¤ì‹œê°„ìœ¼ë¡œ í† í° ë‹¨ìœ„ë¡œ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
import sys

# Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import time

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ìƒìœ„ í´ë”ì˜ .env íŒŒì¼ ì‚¬ìš©)
from pathlib import Path
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

# API í‚¤ í™•ì¸ ë° ì„¤ì •
api_key = os.environ.get("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY not found. Please check .env file")
os.environ["GOOGLE_API_KEY"] = api_key

print("=" * 60)
print("LangChain ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì˜ˆì œ")
print("=" * 60)
print()

# 1. ëª¨ë¸ ì´ˆê¸°í™”
print("ğŸ¤– Gemini ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0.7,
    streaming=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
)
print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")
print()

# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
prompt = ChatPromptTemplate.from_template("{question}")

# 3. Output Parser
output_parser = StrOutputParser()

# 4. ì²´ì¸ êµ¬ì„±
chain = prompt | llm | output_parser

# ì˜ˆì œ 1: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë°
print("=" * 60)
print("ì˜ˆì œ 1: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥")
print("=" * 60)

question1 = "íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§• 5ê°€ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
print(f"ğŸ“ ì§ˆë¬¸: {question1}")
print()
print("ğŸ¤– AI ì‘ë‹µ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°):")
print("-" * 60)

start_time = time.time()

for chunk in chain.stream({"question": question1}):
    print(chunk, end="", flush=True)

elapsed_time = time.time() - start_time
print()
print("-" * 60)
print(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
print()

# ì˜ˆì œ 2: ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ í˜¸ì¶œ ë¹„êµ
print("=" * 60)
print("ì˜ˆì œ 2: ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ í˜¸ì¶œ ì„±ëŠ¥ ë¹„êµ")
print("=" * 60)

question2 = "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
print(f"ğŸ“ ì§ˆë¬¸: {question2}")
print()

# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹
print("[ë°©ì‹ 1] ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥:")
print("-" * 60)
stream_start = time.time()

for chunk in chain.stream({"question": question2}):
    print(chunk, end="", flush=True)

stream_time = time.time() - stream_start
print()
print("-" * 60)
print(f"â±ï¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œê°„: {stream_time:.2f}ì´ˆ")
print()

# ì¼ë°˜ í˜¸ì¶œ ë°©ì‹
print("[ë°©ì‹ 2] ì¼ë°˜ í˜¸ì¶œ ì¶œë ¥:")
print("-" * 60)
invoke_start = time.time()

response = chain.invoke({"question": question2})
print(response)

invoke_time = time.time() - invoke_start
print("-" * 60)
print(f"â±ï¸ ì¼ë°˜ í˜¸ì¶œ ì‹œê°„: {invoke_time:.2f}ì´ˆ")
print()

# ì˜ˆì œ 3: ê¸´ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
print("=" * 60)
print("ì˜ˆì œ 3: ê¸´ ì‘ë‹µì˜ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼")
print("=" * 60)

question3 = "ì›¹ ê°œë°œ ì´ˆë³´ìë¥¼ ìœ„í•œ í•™ìŠµ ë¡œë“œë§µì„ ë‹¨ê³„ë³„ë¡œ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”."
print(f"ğŸ“ ì§ˆë¬¸: {question3}")
print()
print("ğŸ¤– AI ì‘ë‹µ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°):")
print("-" * 60)

chunk_count = 0
start_time = time.time()

for chunk in chain.stream({"question": question3}):
    print(chunk, end="", flush=True)
    chunk_count += 1

elapsed_time = time.time() - start_time
print()
print("-" * 60)
print(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
print(f"ğŸ“¦ ì´ ì²­í¬ ìˆ˜: {chunk_count}ê°œ")
print()


"""
LangSmith íŠœí† ë¦¬ì–¼ - LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§

ìƒì„¸ ê°€ì´ë“œ: langsmith_tutorial.md ì°¸ê³ 
"""

import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_classic.memory import ConversationBufferMemory
from langchain_classic.chains import ConversationChain

load_dotenv()

print("=" * 70)
print("LangSmith íŠœí† ë¦¬ì–¼ - LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§")
print("=" * 70)
print()

def step1_setup():
    """Step 1: LangSmith ì„¤ì • í™•ì¸"""
    print("ğŸ“Œ Step 1: LangSmith ì„¤ì • í™•ì¸")
    print("=" * 70)
    print()

    google_api_key = os.environ.get("GOOGLE_API_KEY")
    langchain_tracing = os.environ.get("LANGCHAIN_TRACING_V2")
    langchain_api_key = os.environ.get("LANGCHAIN_API_KEY")
    langchain_project = os.environ.get("LANGCHAIN_PROJECT", "default")

    print("ğŸ” í™˜ê²½ë³€ìˆ˜ ìƒíƒœ:")
    print(f"  âœ“ GOOGLE_API_KEY: {'ì„¤ì •ë¨' if google_api_key else 'âŒ ì—†ìŒ'}")
    print(f"  âœ“ LANGCHAIN_TRACING_V2: {langchain_tracing or 'âŒ ì—†ìŒ (ì¶”ì  ë¹„í™œì„±í™”)'}")
    print(f"  âœ“ LANGCHAIN_API_KEY: {'ì„¤ì •ë¨' if langchain_api_key else 'âŒ ì—†ìŒ'}")
    print(f"  âœ“ LANGCHAIN_PROJECT: {langchain_project}")
    print()

    if not google_api_key:
        raise ValueError("GOOGLE_API_KEY not found. Please check .env file")

    if langchain_tracing == "true" and langchain_api_key:
        print("âœ… LangSmith ì¶”ì ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"   í”„ë¡œì íŠ¸: {langchain_project}")
        print("   https://smith.langchain.com ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print("âš ï¸ LangSmith ì¶”ì ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("   ìƒì„¸ ì„¤ì • ë°©ë²•ì€ langsmith_tutorial.md íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.")

    print()
    return google_api_key, langchain_tracing == "true"

def step2_basic_tracking(llm):
    """Step 2: ê¸°ë³¸ ì¶”ì  (ë‹¨ì¼ LLM í˜¸ì¶œ)"""
    print("=" * 70)
    print("ğŸ“Œ Step 2: ê¸°ë³¸ ì¶”ì  - ë‹¨ì¼ LLM í˜¸ì¶œ")
    print("=" * 70)
    print()

    print("ğŸ’¬ í…ŒìŠ¤íŠ¸ 2-1: ê°„ë‹¨í•œ ì§ˆë¬¸")
    print("-" * 70)
    question1 = "íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§• 3ê°€ì§€ë¥¼ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜"
    print(f"ì§ˆë¬¸: {question1}")
    print()

    response1 = llm.invoke(question1)
    print(f"ğŸ¤– AI ì‘ë‹µ:\n{response1.content}")
    print()

    print("ğŸ’¬ í…ŒìŠ¤íŠ¸ 2-2: ë³µì¡í•œ ì§ˆë¬¸")
    print("-" * 70)
    question2 = "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì„ ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì¤˜"
    print(f"ì§ˆë¬¸: {question2}")
    print()

    response2 = llm.invoke(question2)
    print(f"ğŸ¤– AI ì‘ë‹µ:\n{response2.content}")
    print()

def step3_streaming_tracking(llm):
    """Step 3: ìŠ¤íŠ¸ë¦¬ë° ì¶”ì """
    print("=" * 70)
    print("ğŸ“Œ Step 3: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶”ì ")
    print("=" * 70)
    print()

    question = "ì›¹ ê°œë°œ ì´ˆë³´ìë¥¼ ìœ„í•œ í•™ìŠµ ë¡œë“œë§µì„ ë‹¨ê³„ë³„ë¡œ ì‘ì„±í•´ì¤˜"
    print(f"ğŸ’¬ ì§ˆë¬¸: {question}")
    print()
    print("ğŸ¤– AI ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°):")
    print("-" * 70)

    for chunk in llm.stream(question):
        print(chunk.content, end="", flush=True)

    print()
    print("-" * 70)
    print()

def step4_conversation_tracking(llm):
    """Step 4: ëŒ€í™” ì²´ì¸ ì¶”ì """
    print("=" * 70)
    print("ğŸ“Œ Step 4: ëŒ€í™” ì²´ì¸ ì¶”ì  (ConversationChain)")
    print("=" * 70)
    print()

    memory = ConversationBufferMemory()
    conversation = ConversationChain(
        llm=llm,
        memory=memory,
        verbose=False
    )

    dialogue = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” íŒŒì´ì¬ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”.",
        "íŒŒì´ì¬ìœ¼ë¡œ ë¬´ì—‡ì„ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?",
        "ì›¹ ê°œë°œì„ í•˜ë ¤ë©´ ì–´ë–¤ í”„ë ˆì„ì›Œí¬ë¥¼ ë°°ì›Œì•¼ í•˜ë‚˜ìš”?",
        "Djangoì™€ Flask ì¤‘ ì–´ë–¤ ê²ƒì„ ì¶”ì²œí•˜ì‹œë‚˜ìš”?"
    ]

    print("ğŸ’¬ ì—°ì† ëŒ€í™” ì‹œì‘:")
    print("=" * 70)

    for i, question in enumerate(dialogue, 1):
        print(f"\n[ëŒ€í™” {i}]")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {question}")
        answer = conversation.predict(input=question)
        print(f"ğŸ¤– AI: {answer}")
        print("-" * 70)

    print()

def step5_advanced_features(llm):
    """Step 5: ê³ ê¸‰ ê¸°ëŠ¥ (íƒœê·¸, ë©”íƒ€ë°ì´í„°)"""
    print("=" * 70)
    print("ğŸ“Œ Step 5: ê³ ê¸‰ ì¶”ì  ê¸°ëŠ¥ (íƒœê·¸, ë©”íƒ€ë°ì´í„°)")
    print("=" * 70)
    print()

    print("ğŸ·ï¸ í…ŒìŠ¤íŠ¸ 5-1: íƒœê·¸ë¥¼ ì‚¬ìš©í•œ ë¶„ë¥˜")
    print("-" * 70)
    question = "LangChainì´ ë­ì•¼?"
    print(f"ì§ˆë¬¸: {question}")
    print("íƒœê·¸: ['tutorial', 'langchain', 'beginner']")
    print()

    response = llm.invoke(
        question,
        config={"tags": ["tutorial", "langchain", "beginner"]}
    )
    print(f"ğŸ¤– AI ì‘ë‹µ:\n{response.content}")
    print()

    print("ğŸ“Š í…ŒìŠ¤íŠ¸ 5-2: ë©”íƒ€ë°ì´í„° ì¶”ê°€")
    print("-" * 70)
    question = "Pythonì˜ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ëŠ”?"
    print(f"ì§ˆë¬¸: {question}")
    print("ë©”íƒ€ë°ì´í„°: user_id=user_123, session=session_456")
    print()

    response = llm.invoke(
        question,
        config={
            "metadata": {
                "user_id": "user_123",
                "session": "session_456",
                "environment": "development"
            }
        }
    )
    print(f"ğŸ¤– AI ì‘ë‹µ:\n{response.content}")
    print()

def step6_dashboard_guide():
    """Step 6: LangSmith ëŒ€ì‹œë³´ë“œ í™œìš© ê°€ì´ë“œ"""
    print("=" * 70)
    print("ğŸ“Œ Step 6: LangSmith ëŒ€ì‹œë³´ë“œ í™œìš©ë²•")
    print("=" * 70)
    print()

    print("ğŸŒ ëŒ€ì‹œë³´ë“œ ì ‘ì†: https://smith.langchain.com")
    print()
    print("ğŸ“Š í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´:")
    print("   - ì´ ì‹¤í–‰ íšŸìˆ˜ ë° ì„±ê³µ/ì‹¤íŒ¨ìœ¨")
    print("   - í‰ê·  ì‘ë‹µ ì‹œê°„")
    print("   - í† í° ì‚¬ìš©ëŸ‰ ë° ì˜ˆìƒ ë¹„ìš©")
    print("   - ê°œë³„ ì‹¤í–‰ì˜ ì…ë ¥/ì¶œë ¥ ë°ì´í„°")
    print("   - ì²´ì¸ ì‹¤í–‰ íë¦„ ì‹œê°í™”")
    print("   - ì—ëŸ¬ ì¶”ì  ë° ë””ë²„ê¹… ì •ë³´")
    print()
    print("ğŸ’¡ ìƒì„¸ í™œìš©ë²•ì€ langsmith_tutorial.md íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.")
    print()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        api_key, tracing_enabled = step1_setup()

        print("ğŸ¤– Gemini ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        llm = ChatGoogleGenerativeAI(
            model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite"),
            temperature=0.7
        )
        print("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")
        print()

        step2_basic_tracking(llm)
        step3_streaming_tracking(llm)
        step4_conversation_tracking(llm)
        step5_advanced_features(llm)
        step6_dashboard_guide()

        print("=" * 70)
        print("ğŸ‰ íŠœí† ë¦¬ì–¼ ì™„ë£Œ!")
        print("=" * 70)
        print()

        if tracing_enabled:
            print("âœ… LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ëª¨ë“  ì‹¤í–‰ ë‚´ì—­ì„ í™•ì¸í•˜ì„¸ìš”:")
            print("   https://smith.langchain.com")
            print()
            print("ğŸ“Š í™•ì¸ ê°€ëŠ¥í•œ ë‚´ì—­:")
            print("   - Step 2: ë‹¨ì¼ LLM í˜¸ì¶œ 2ê±´")
            print("   - Step 3: ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ 1ê±´")
            print("   - Step 4: ëŒ€í™” ì²´ì¸ (4í„´)")
            print("   - Step 5: íƒœê·¸/ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ í˜¸ì¶œ 2ê±´")
        else:
            print("âš ï¸ LangSmith ì¶”ì ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì— LangSmith ì„¤ì •ì„ ì¶”ê°€í•˜ë©´ ì¶”ì  ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("   ìƒì„¸ ì„¤ì • ë°©ë²•: langsmith_tutorial.md")

        print()
        print("ğŸ“š í•™ìŠµ ë‚´ìš© ì •ë¦¬:")
        print("   1. LangSmithëŠ” í™˜ê²½ë³€ìˆ˜ë§Œìœ¼ë¡œ ìë™ ì¶”ì ")
        print("   2. ëª¨ë“  LLM í˜¸ì¶œ(invoke, stream)ì´ ê¸°ë¡ë¨")
        print("   3. ConversationChain ê°™ì€ ë³µì¡í•œ ì²´ì¸ë„ ì‹œê°í™”")
        print("   4. íƒœê·¸ì™€ ë©”íƒ€ë°ì´í„°ë¡œ ì‹¤í–‰ ë¶„ë¥˜ ë° ê²€ìƒ‰")
        print("   5. ëŒ€ì‹œë³´ë“œì—ì„œ ì„±ëŠ¥, ë¹„ìš©, ì—ëŸ¬ ë¶„ì„ ê°€ëŠ¥")
        print("=" * 70)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print()
        print("ğŸ’¡ ë¬¸ì œ í•´ê²°:")
        print("   1. .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("   2. LangSmithë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ LANGCHAIN_API_KEYë„ í•„ìš”")
        print("   3. ìƒì„¸ ë‚´ìš©: langsmith_tutorial.md ì°¸ê³ ")

if __name__ == "__main__":
    main()

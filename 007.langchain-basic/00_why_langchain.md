# 00_why_langchain.py ì„¤ëª…

## ê°œìš”

Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ LangChainì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì˜ ì°¨ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

---

## Part 1: Gemini API ì§ì ‘ ì‚¬ìš© (ìµœì‹  google-genai SDK)

### íŠ¹ì§•
- ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- Gemini ì „ìš© ê¸°ëŠ¥ í™œìš© ê°€ëŠ¥
- í•™ìŠµ ëª©ì ìœ¼ë¡œ ì¢‹ìŒ

### ì½”ë“œ êµ¬ì¡°
```python
from google import genai
from google.genai import types

client = genai.Client(api_key=api_key)
system_instruction = "ë„ˆëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

# ë‹¨ì¼ ì§ˆë¬¸
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents="íŒŒì´ì¬ì´ë€?",
    config=types.GenerateContentConfig(system_instruction=system_instruction)
)

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
history = []
history.append(types.Content(role="user", parts=[types.Part(text="íŒŒì´ì¬ì´ë€?")]))
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=history,
    config=types.GenerateContentConfig(system_instruction=system_instruction)
)
history.append(types.Content(role="model", parts=[types.Part(text=response.text)]))
```

### ë¬¸ì œì 
- âŒ ë‹¤ë¥¸ LLM(OpenAI, Claude ë“±)ìœ¼ë¡œ ë°”ê¾¸ë ¤ë©´ ì½”ë“œ ì „ì²´ ìˆ˜ì •
- âŒ íˆìŠ¤í† ë¦¬ í˜•ì‹ì´ Gemini ì „ìš© (`types.Content`)
- âŒ ê³ ê¸‰ ê¸°ëŠ¥(Chain, Agent, RAG)ì„ ì§ì ‘ êµ¬í˜„í•´ì•¼ í•¨
- âŒ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ì¶œë ¥ íŒŒì‹± ë“± ë§¤ë²ˆ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•¨

---

## Part 2: LangChain ì‚¬ìš© (ê¶Œì¥ ë°©ì‹)

### íŠ¹ì§•
- í‘œì¤€í™”ë˜ê³  ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€
- ë‹¤ë¥¸ LLMìœ¼ë¡œ ì‰½ê²Œ êµì²´
- ê³ ê¸‰ ê¸°ëŠ¥(Chain, RAG) ë°”ë¡œ ì‚¬ìš©
- í”„ë¡œë•ì…˜ í™˜ê²½ì— ì í•©

### ì½”ë“œ êµ¬ì¡°
```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage

langchain_model = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0.7,
    google_api_key=api_key
)

# ë‹¨ì¼ ì§ˆë¬¸
response = langchain_model.invoke("íŒŒì´ì¬ì´ë€?")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
messages = [
    SystemMessage(content="ë„ˆëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    HumanMessage(content="íŒŒì´ì¬ì´ë€?")
]
response1 = langchain_model.invoke(messages)
messages.append(response1)
messages.append(HumanMessage(content="ê·¸ëŸ¼ ìë°”ëŠ”?"))
response2 = langchain_model.invoke(messages)
```

### ì¥ì 
- âœ… í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ - ë‹¤ë¥¸ LLMìœ¼ë¡œ êµì²´ ì‰¬ì›€
- âœ… í‘œì¤€ ë©”ì‹œì§€ í˜•ì‹ - `SystemMessage`, `HumanMessage`, `AIMessage`
- âœ… í’ë¶€í•œ ìƒíƒœê³„ - Chain, Agent, RAG ë“± ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, íŒŒì„œ ë“±

---

## Part 3: ëª¨ë¸ êµì²´ê°€ ì–¼ë§ˆë‚˜ ì‰¬ìš´ê°€?

### âŒ Gemini API ì§ì ‘ ì‚¬ìš©
```python
from google import genai
from google.genai import types

client = genai.Client(api_key=api_key)
history = [types.Content(role="user", parts=[types.Part(text="ì•ˆë…•")])]
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=history
)

# â†’ OpenAIë¡œ êµì²´í•˜ë ¤ë©´?
# ì „ì²´ ì½”ë“œ ë‹¤ì‹œ ì‘ì„±! (openai.chat.completions.create ë“±)
```

### âœ… LangChain ì‚¬ìš©
```python
# Gemini
from langchain_google_genai import ChatGoogleGenerativeAI
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

# OpenAIë¡œ êµì²´? ë”± 2ì¤„ë§Œ ë°”ê¾¸ë©´ ë¨!
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4")

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼!
response = llm.invoke("ì•ˆë…•")
```

---

## Part 4: ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤ - ì–¸ì œ LangChainì„ ì‚¬ìš©í•˜ë‚˜?

### âœ… LangChain ì‚¬ìš©ì„ ê¶Œì¥:
- í”„ë¡œë•ì…˜ í™˜ê²½ (ìœ ì§€ë³´ìˆ˜ ì¤‘ìš”)
- ì—¬ëŸ¬ LLM í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸ í•„ìš”
- Chain, Agent, RAG ë“± ê³ ê¸‰ ê¸°ëŠ¥ í•„ìš”
- íŒ€ í”„ë¡œì íŠ¸ (í‘œì¤€í™”ëœ ì½”ë“œ)

### âŒ Gemini API ì§ì ‘ ì‚¬ìš©ë„ ê´œì°®ìŒ:
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… (ë‹¨ìˆœ í…ŒìŠ¤íŠ¸)
- Gemini ì „ìš© ê¸°ëŠ¥ ì‚¬ìš© (Thinking ëª¨ë“œ ë“±)
- í•™ìŠµ ëª©ì  (API ë™ì‘ ì›ë¦¬ ì´í•´)
- ì´ˆê²½ëŸ‰ ì• í”Œë¦¬ì¼€ì´ì…˜

ğŸ’¡ **ê¶Œì¥: í•™ìŠµì€ Gemini APIë¡œ, ì‹¤ì „ì€ LangChainìœ¼ë¡œ!**

---

## Part 5: LangChainìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤ (ë¯¸ë¦¬ë³´ê¸°)

### 1ï¸âƒ£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Step 5-2)
```python
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_template("ë‹¤ìŒì„ ìš”ì•½: {text}")
```

### 2ï¸âƒ£ LCEL ì²´ì¸ (Step 5-3)
```python
chain = prompt | llm | output_parser
result = chain.invoke({"text": "..."})
```

### 3ï¸âƒ£ ë„êµ¬(Tool) ì‚¬ìš© (Step 6)
```python
from langchain.tools import tool

@tool
def calculator(expression: str) -> float:
    return eval(expression)
```

### 4ï¸âƒ£ RAG ì‹œìŠ¤í…œ (Step 7)
```python
retriever = vector_store.as_retriever()
chain = retriever | llm
```

### 5ï¸âƒ£ ì—ì´ì „íŠ¸ (ê³ ê¸‰)
```python
agent = initialize_agent(tools, llm)
agent.run("í˜„ì¬ ë‚ ì”¨ ì•Œë ¤ì¤˜")
```

---

## ì •ë¦¬

### Gemini API ì§ì ‘ ì‚¬ìš©:
- ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- Gemini ì „ìš© ê¸°ëŠ¥ í™œìš© ê°€ëŠ¥
- í•™ìŠµ ëª©ì ìœ¼ë¡œ ì¢‹ìŒ

### LangChain ì‚¬ìš©:
- í‘œì¤€í™”ë˜ê³  ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€
- ë‹¤ë¥¸ LLMìœ¼ë¡œ ì‰½ê²Œ êµì²´
- ê³ ê¸‰ ê¸°ëŠ¥(Chain, RAG) ë°”ë¡œ ì‚¬ìš©
- í”„ë¡œë•ì…˜ í™˜ê²½ì— ì í•©

ğŸ¯ **ì´ì œë¶€í„°ëŠ” LangChain ë°©ì‹ìœ¼ë¡œ ë°°ì›Œë´…ì‹œë‹¤!**

---

## ë‹¤ìŒ ë‹¨ê³„
```bash
python 007.langchain-basic/01_langchain_basic.py
```

"""
Step 5-2-4: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì•„ ì¶œë ¥í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI

# í™˜ê²½ ì„¤ì •
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# ëª¨ë¸ ë° íˆìŠ¤í† ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •
model = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite"),
    temperature=0.7,
    google_api_key=api_key,
    model_kwargs={
        "system_instruction": (
            "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼. ê³µê°ì ìœ¼ë¡œ ë‹µí•˜ê³ , "
            "ëª¨í˜¸í•˜ë©´ ì§§ê²Œ ë˜ë¬¼ì–´ë´. í•„ìš”í•˜ë©´ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•´ì¤˜."
        )
    },
)

store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

with_message_history = RunnableWithMessageHistory(model, get_session_history)

print("=" * 70)
print("Step 4: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ")
print("=" * 70)
print()

# ============================================================
# ì„¸ì…˜ abc2 ì¬í˜„ (ì´ì „ ëŒ€í™” ë§¥ë½)
# ============================================================
print("ğŸ“Œ 4-1. ì„¸ì…˜ abc2 ì¬í˜„")
print("-" * 70)

config = {"configurable": {"session_id": "abc2"}}

# ì´ì „ ëŒ€í™” ì¬í˜„
with_message_history.invoke(
    [HumanMessage(content="ì•ˆë…•? ë‚œ ê¹€ì² ìˆ˜ì´ì•¼.")],
    config,
)

print("âœ… ì„¸ì…˜ abc2 ì¤€ë¹„ ì™„ë£Œ")
print()

# ============================================================
# ì¼ë°˜ ì‘ë‹µ (ë¹„êµìš©)
# ============================================================
print("ğŸ“Œ 4-2. ì¼ë°˜ ì‘ë‹µ ë°©ì‹ (invoke)")
print("-" * 70)

print("ğŸ‘¤ ì‚¬ìš©ì: íŒŒì´ì¬ì˜ ì¥ì ì„ ë§í•´ì¤˜")
print("ğŸ¤– AI ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
print()

response = with_message_history.invoke(
    [HumanMessage(content="íŒŒì´ì¬ì˜ ì¥ì ì„ ë§í•´ì¤˜")],
    config,
)

print(f"ğŸ¤– AI: {response.content[:200]}...")
print()
print("ğŸ’¡ ì¼ë°˜ ë°©ì‹: ì „ì²´ ì‘ë‹µì´ ì™„ì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°")
print()

# ============================================================
# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
# ============================================================
print("ğŸ“Œ 4-3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°©ì‹ (stream)")
print("-" * 70)

print("ğŸ‘¤ ì‚¬ìš©ì: ë‚´ê°€ ì–´ëŠ ë‚˜ë¼ ì‚¬ëŒì¸ì§€ ì¶”ì¸¡í•˜ê³ , ê·¸ ë‚˜ë¼ ë¬¸í™” í•œ ê°€ì§€ë¥¼ ë§í•´ì¤˜")
print()
print("ğŸ¤– AI (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°): ", end="", flush=True)

for chunk in with_message_history.stream(
    [HumanMessage(content="ë‚´ê°€ ì–´ëŠ ë‚˜ë¼ ì‚¬ëŒì¸ì§€ ì¶”ì¸¡í•˜ê³ , ê·¸ ë‚˜ë¼ ë¬¸í™” í•œ ê°€ì§€ë¥¼ ë§í•´ì¤˜")],
    config,
):
    print(chunk.content, end="", flush=True)

print("\n")
print("ğŸ’¡ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹: ì‘ë‹µì´ ìƒì„±ë˜ëŠ” ëŒ€ë¡œ ì¦‰ì‹œ ì¶œë ¥")
print()

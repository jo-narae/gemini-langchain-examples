# -*- coding: utf-8 -*-
"""
Step 3: ë„êµ¬ í˜¸ì¶œ ê¸°ë³¸ (ìˆ˜ë™ ë°©ì‹)

ëª¨ë¸ì— ë„êµ¬ë¥¼ ë°”ì¸ë”©í•˜ê³ , AIê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ë‹µë³€í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import os
import sys
sys.stdout.reconfigure(encoding='utf-8')
from pathlib import Path
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from datetime import datetime
import pytz

# í™˜ê²½ì„¤ì •
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("âŒ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite"),
    temperature=0.7,
    google_api_key=api_key,
)

# ë„êµ¬ ì •ì˜
@tool
def get_current_time(timezone: str, location: str) -> str:
    """í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        timezone (str): íƒ€ì„ì¡´ (ì˜ˆ: 'Asia/Seoul')
        location (str): ì§€ì—­ëª…
    """
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        return f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
    except Exception as e:
        return f"ì‹œê°„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

print("=" * 70)
print("Step 3: ë„êµ¬ í˜¸ì¶œ ê¸°ë³¸")
print("=" * 70)
print()

# ë„êµ¬ë¥¼ ëª¨ë¸ì— ë°”ì¸ë”©
tools = [get_current_time]
tool_dict = {"get_current_time": get_current_time}
llm_with_tools = llm.bind_tools(tools)

print("ğŸ”— ë„êµ¬ê°€ ëª¨ë¸ì— ë°”ì¸ë”©ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[tool.name for tool in tools]}")
print()

# ì‚¬ìš©ì ì§ˆë¬¸
messages = [
    SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤."),
    HumanMessage("ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?"),
]

print("ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸: ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?")
print()

# AI ì‘ë‹µ (ë„êµ¬ í˜¸ì¶œ í¬í•¨)
response = llm_with_tools.invoke(messages)
messages.append(response)

print(f"ğŸ¤– AI ì‘ë‹µ: {response.content}")

# ë„êµ¬ í˜¸ì¶œ í™•ì¸
if hasattr(response, 'tool_calls') and response.tool_calls:
    print(f"ğŸ”§ í˜¸ì¶œëœ ë„êµ¬ ìˆ˜: {len(response.tool_calls)}")
    print()
    
    # ê° ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
    for tool_call in response.tool_calls:
        selected_tool = tool_dict[tool_call["name"]]
        print(f"ğŸ› ï¸  ë„êµ¬ í˜¸ì¶œ: {tool_call['name']}")
        print(f"ğŸ“¥ ì „ë‹¬ëœ ì¸ì: {tool_call['args']}")
        
        # ë„êµ¬ ì‹¤í–‰
        tool_msg = selected_tool.invoke(tool_call)
        messages.append(tool_msg)
        print(f"ğŸ“¤ ë„êµ¬ ê²°ê³¼: {tool_msg.content}")
        print()
    
    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
    print("ğŸ”„ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
    final_response = llm_with_tools.invoke(messages)
    print(f"ğŸ¯ ìµœì¢… ë‹µë³€: {final_response.content}")
else:
    print("â„¹ï¸  ë„êµ¬ í˜¸ì¶œì´ ì—†ì—ˆìŠµë‹ˆë‹¤.")
